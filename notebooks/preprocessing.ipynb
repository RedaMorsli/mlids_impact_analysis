{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:14:44.226279900Z",
     "start_time": "2024-05-02T15:14:39.177489300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\BruteForce\\21-03-2024-3h\n",
      "(221552, 80)\n",
      "class                    2\n",
      "dst_port              8153\n",
      "protocol                 2\n",
      "timestamp            20187\n",
      "flow_duration       101339\n",
      "                     ...  \n",
      "cwe_flag_count           1\n",
      "subflow_fwd_pkts       231\n",
      "subflow_bwd_pkts       233\n",
      "subflow_fwd_byts      5865\n",
      "subflow_bwd_byts      6176\n",
      "Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import data_utils as data\n",
    "\n",
    "source = data.Data.BF_1.value[0]\n",
    "\n",
    "print(source['path'])\n",
    "\n",
    "df_flow, df_cpu, df_memory, df_bw_in, df_bw_out, df_pkts_in, df_pkts_out, df_iops_rw, df_iops, df_tp_rw, df_tp = data.get_data(source['path'])\n",
    "\n",
    "save_directory = source['path'].replace('data', 'output' + '\\\\')\n",
    "start_date = source['start_time']\n",
    "end_date = source['end_time']\n",
    "\n",
    "print(df_flow.shape)\n",
    "df_flow.head()\n",
    "print(df_flow.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-25T18:53:26.189583300Z",
     "start_time": "2024-04-25T18:53:23.541959100Z"
    }
   },
   "source": [
    "Time filtering"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  cpu_classifier  cpu_controller  cpu_database  \\\n",
      "0  2024-03-21 07:25:45          0.0104         0.00337      0.000925   \n",
      "1  2024-03-21 07:25:50          0.0104         0.00337      0.000925   \n",
      "2  2024-03-21 07:25:55          0.0104         0.00337      0.000925   \n",
      "3  2024-03-21 07:26:00          0.0180         0.00369      0.000554   \n",
      "4  2024-03-21 07:26:05          0.0180         0.00369      0.000554   \n",
      "\n",
      "   cpu_sniffer  cpu_total  memory_classifier  memory_controller  \\\n",
      "0       0.0138   0.028495         4741091328           71786496   \n",
      "1       0.0138   0.028495         4741091328           71786496   \n",
      "2       0.0138   0.028495         4742586368           71786496   \n",
      "3       0.0080   0.030244         4742586368           71786496   \n",
      "4       0.0080   0.030244         4742586368           71806976   \n",
      "\n",
      "   memory_database  memory_sniffer  ...  iops_rw_database  iops_rw_sniffer  \\\n",
      "0         37847040      1399795712  ...                 2                0   \n",
      "1         37855232      1399795712  ...                 2                0   \n",
      "2         37855232      1399795712  ...                 2                0   \n",
      "3         37855232      1399795712  ...                 2                0   \n",
      "4         37855232      1515405312  ...                 1                0   \n",
      "\n",
      "   iops_rw_total  iops_Reads  tp_rw_classifier  tp_rw_controller  \\\n",
      "0              2           0                 0                 0   \n",
      "1              2           0                 0                 0   \n",
      "2              2           0                 0                 0   \n",
      "3              2           0                 0                 0   \n",
      "4              1           0                 0                 0   \n",
      "\n",
      "   tp_rw_database  tp_rw_sniffer  tp_rw_total  tp_Reads  \n",
      "0           12761              0        12761       0.0  \n",
      "1           11629              0        11629       0.0  \n",
      "2           11629              0        11629       0.0  \n",
      "3           11629              0        11629       0.0  \n",
      "4           10097              0        10097       0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_flow['timestamp'] = pd.to_datetime(df_flow['timestamp'])\n",
    "\n",
    "print(df_flow.shape)\n",
    "\n",
    "# Filter rows between start_date and end_date\n",
    "df_flow = df_flow[(df_flow['timestamp'] >= start_date) & (df_flow['timestamp'] <= end_date)]\n",
    "\n",
    "print(df_flow.shape)\n",
    "\n",
    "# Replace class values ([0] -> 0 and [1] -> 1)\n",
    "df_flow['class'] = df_flow['class'].replace({'[0]': 0, '[1]': 1})\n",
    "# filtered_df.head()\n",
    "df_flow[df_flow['class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Only for brute force data\n",
    "# df_sorted = df_flow.sort_values(by='timestamp')\n",
    "# split_index = len(df_sorted) // 2\n",
    "# df_second_half = df_sorted.iloc[split_index:]\n",
    "# df_second_half.reset_index(drop=True, inplace=True)\n",
    "# df_flow = df_second_half"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Save flow data\n",
    "df_flow.to_csv(save_directory + \"flows.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Column filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_flow = df_flow.get([\"timestamp\", \"class\", \"flow_duration\", \"flow_byts_s\", \"flow_pkts_s\", \"tot_fwd_pkts\", \"tot_bwd_pkts\", \"totlen_fwd_pkts\", \"totlen_bwd_pkts\"])\n",
    "# print(df_flow.shape)\n",
    "# df_flow.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Prepare resource data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_cpu = pd.read_csv(CPU_PATH)\n",
    "df_cpu = df_cpu.rename(columns={'Time': 'timestamp'})\n",
    "df_cpu = df_cpu.drop(\"Value 1\", axis=1)\n",
    "# Merge CPU values by sum\n",
    "df_cpu[\"cpu_total\"] = df_cpu.drop(\"timestamp\", axis=1).sum(axis=1)\n",
    "df_cpu.head()\n",
    "# Save CPU data\n",
    "df_cpu.to_csv(save_directory + \"cpu.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bw_in = pd.read_csv(BW_IN_PATH)\n",
    "df_bw_in = df_bw_in.rename(columns={'Time': 'timestamp'})\n",
    "df_bw_in.head()\n",
    "df_bw_in.to_csv(save_directory + \"bw_in.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bw_out = pd.read_csv(BW_OUT_PATH)\n",
    "df_bw_out = df_bw_out.rename(columns={'Time': 'timestamp'})\n",
    "df_bw_out.head()\n",
    "df_bw_out.to_csv(save_directory + \"bw_in.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert timestamp columns to datetime objects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cpu['timestamp'] = pd.to_datetime(df_cpu['timestamp'])\n",
    "df_flow['timestamp'] = pd.to_datetime(df_flow['timestamp'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Data mapping (method 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_flow1 = df_flow\n",
    "\n",
    "# Create a new column in the network dataframe to store associated cpu records\n",
    "df_flow1['cpu'] = None\n",
    "\n",
    "# Loop over each flow row\n",
    "for index, flow_row in df_flow1.iterrows():\n",
    "    # Find the nearest cpu record according to time\n",
    "    nearest_cpu_record = df_cpu.iloc[(df_cpu['timestamp'] - flow_row['timestamp']).abs().argsort()[0]]\n",
    "\n",
    "    # Assign the nearest cpu record to the current flow row\n",
    "    df_flow1.at[index, 'cpu'] = nearest_cpu_record['cpu_total']\n",
    "\n",
    "# Convert all timestamps to total seconds from the first timestamp\n",
    "df_flow1 = df_flow1.sort_values(by='timestamp')\n",
    "first_timestamp = df_flow1['timestamp'].iloc[0]\n",
    "df_flow1['timestamp'] = (df_flow1['timestamp'] - first_timestamp).dt.total_seconds()\n",
    "\n",
    "# Save flow data\n",
    "df_flow1.to_csv(save_directory + \"data1.csv\", index=False)\n",
    "\n",
    "# Print the updated network dataframe with associated cpu records\n",
    "print(df_flow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data mapping (method 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cpu1 = df_cpu\n",
    "\n",
    "# Function to aggregate flows for each CPU record\n",
    "def aggregate_flows(cpu_row, network_df):\n",
    "    # Get the current and next CPU timestamps\n",
    "    current_timestamp = cpu_row['timestamp']\n",
    "    next_timestamp = df_cpu1.loc[cpu_row.name + 1, 'timestamp'] if cpu_row.name + 1 < len(df_cpu) else pd.Timestamp.max\n",
    "\n",
    "    # Filter flows that fall within the time interval\n",
    "    flows_in_interval = network_df[(network_df['timestamp'] >= current_timestamp) & (network_df['timestamp'] < next_timestamp)]\n",
    "\n",
    "    # Aggregate flow values\n",
    "    row = flows_in_interval.drop(['timestamp', 'protocol', 'dst_port'], axis=1).sum()\n",
    "\n",
    "     # Add a column for the number of aggregated flows\n",
    "    row['num_flows'] = len(flows_in_interval)\n",
    "\n",
    "    if len(flows_in_interval) != 0:\n",
    "        features = row.index[(row.index != 'num_flows') & (row.index != 'class')]\n",
    "        row[features] = row[features] / row['num_flows']\n",
    "\n",
    "    return row\n",
    "\n",
    "# Loop over each CPU row\n",
    "for index, cpu_row in df_cpu1.iterrows():\n",
    "    # Aggregate flows for the current CPU row\n",
    "    aggregated_values = aggregate_flows(cpu_row, df_flow)\n",
    "\n",
    "    # Add aggregated flow values to the CPU row\n",
    "    df_cpu1.loc[index, aggregated_values.index] = aggregated_values.values\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_cpu1.fillna(0, inplace=True)\n",
    "\n",
    "# Convert all timestamps to total seconds from the first timestamp\n",
    "df_cpu1 = df_cpu1.sort_values(by='timestamp')\n",
    "first_timestamp = df_cpu1['timestamp'].iloc[0]\n",
    "df_cpu1['timestamp'] = (df_cpu1['timestamp'] - first_timestamp).dt.total_seconds()\n",
    "\n",
    "# Save flow data\n",
    "df_cpu1.to_csv(save_directory + \"data2.csv\", index=False)\n",
    "\n",
    "# Print the updated CPU dataframe\n",
    "print(df_cpu1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
